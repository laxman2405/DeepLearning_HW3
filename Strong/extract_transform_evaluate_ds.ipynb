{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b214087-72af-4cf7-a0fc-4670a408c689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from evaluate import load\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class SpokenSquad(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][i]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][i]),\n",
    "            'start_positions': torch.tensor(self.encodings['start_positions'][i]),\n",
    "            'end_positions': torch.tensor(self.encodings['end_positions'][i])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "class QAModel(nn.Module):\n",
    "    def __init__(self, bert_base_model, device):\n",
    "        super(QAModel, self).__init__()\n",
    "        self.bert = bert_base_model\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs.start_logits, outputs.end_logits\n",
    "\n",
    "    def find_focal_loss(self, start_logits, end_logits, start_positions, end_positions, gamma=1):\n",
    "        start_soft_probs = 1 - nn.Softmax(dim=1)(start_logits)\n",
    "        end_soft_probs = 1 - nn.Softmax(dim=1)(end_logits)\n",
    "        start_log_probs = nn.LogSoftmax(dim=1)(start_logits)\n",
    "        end_log_probs = nn.LogSoftmax(dim=1)(end_logits)\n",
    "        nll_loss = nn.NLLLoss()\n",
    "        \n",
    "        start_loss = nll_loss(torch.pow(start_soft_probs, gamma) * start_log_probs, start_positions)\n",
    "        end_loss = nll_loss(torch.pow(end_soft_probs, gamma) * end_log_probs, end_positions)\n",
    "    \n",
    "        return (start_loss + end_loss) / 2\n",
    "\n",
    "    def evaluate_model(self, dataloader, tokenizer):\n",
    "        self.eval()\n",
    "        f1_scores = []\n",
    "        pred_true_pairs = []\n",
    "        wer_metric = load(\"wer\")\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader, desc='Evaluating Model!'):\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                start_labels = batch['start_positions'].to(self.device)\n",
    "                end_labels = batch['end_positions'].to(self.device)\n",
    "\n",
    "                start, end = self(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                start_preds = torch.argmax(start, dim=1)\n",
    "                end_preds = torch.argmax(end, dim=1)\n",
    "\n",
    "                i = 0\n",
    "                while i < input_ids.size(0):\n",
    "                    predicted = tokenizer.decode(input_ids[i][start_preds[i]:end_preds[i]+1])\n",
    "                    actual = tokenizer.decode(input_ids[i][start_labels[i]:end_labels[i]+1])\n",
    "                    \n",
    "                    pred_true_pairs.append([predicted, actual])\n",
    "                    f1_scores.append(find_f1_score(predicted, actual))\n",
    "                    i += 1\n",
    "                    \n",
    "        predicted_ans = [pair[0] if pair[0] else \"$\" for pair in pred_true_pairs]\n",
    "        actual_ans = [pair[1] if pair[1] else \"$\" for pair in pred_true_pairs]\n",
    "        wer_score = wer_metric.compute(predictions=predicted_ans, references=actual_ans)\n",
    "        avg_f1_score = sum(f1_scores) / len(f1_scores) if f1_scores else 0\n",
    "        return avg_f1_score, wer_score\n",
    "        \n",
    "def collect_and_find_positions(file_path, tokenizer, max_length):\n",
    "    passages, queries, responses = [], [], []\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    for topic in data['data']:\n",
    "        for paragraph in topic['paragraphs']:\n",
    "            passage = paragraph['context'].lower()\n",
    "            for qa in paragraph['qas']:\n",
    "                query = qa['question'].lower()\n",
    "                for answer in qa['answers']:\n",
    "                    answer_text = answer['text'].lower()\n",
    "                    passages.append(passage)\n",
    "                    queries.append(query)\n",
    "                    responses.append({\n",
    "                        'text': answer_text,\n",
    "                        'answer_start': answer['answer_start'],\n",
    "                        'answer_end': answer['answer_start'] + len(answer_text)\n",
    "                    })\n",
    "\n",
    "    passages_trunc=[]\n",
    "    for i in range(len(passages)):\n",
    "        if(len(passages[i])>512):\n",
    "            answer_start=responses[i]['answer_start']\n",
    "            answer_end=responses[i]['answer_start']+len(responses[i]['text'])\n",
    "            mid=(answer_start+answer_end)//2\n",
    "            paragraph_start=max(0,min(mid - max_length//2,len(passages[i])-max_length))\n",
    "            paragraph_end = paragraph_start + max_length \n",
    "            passages_trunc.append(passages[i][paragraph_start:paragraph_end])\n",
    "            responses[i]['answer_start']=((512/2)-len(responses[i])//2)\n",
    "        else:\n",
    "            passages_trunc.append(passages[i])\n",
    "\n",
    "    encodings = tokenizer(queries, passages_trunc, max_length = max_length,truncation=True,padding=True, return_offsets_mapping=False, stride = 128)\n",
    "    for idx, response in enumerate(responses):\n",
    "        start_pos, end_pos = 0, 0\n",
    "        answer_tokens = tokenizer(response['text'], max_length=max_length, truncation=True, padding=True)\n",
    "        answer_ids = answer_tokens['input_ids'][1:-1]\n",
    "        \n",
    "        for start_idx in range(len(encodings['input_ids'][idx]) - len(answer_ids) + 1):\n",
    "            if encodings['input_ids'][idx][start_idx + 1 : start_idx + 1 + len(answer_ids)] == answer_ids:\n",
    "                start_pos = start_idx + 1\n",
    "                end_pos = start_idx + 1 + len(answer_ids)\n",
    "                break\n",
    "        \n",
    "        start_positions.append(start_pos)\n",
    "        end_positions.append(end_pos)\n",
    "\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "    return encodings\n",
    "\n",
    "def filter_data(text):\n",
    "    text = re.sub(r'\\b(a|an|the)\\b', ' ', text.lower())\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def find_f1_score(predicted_answer, actual_answer):\n",
    "    predicted = filter_data(predicted_answer).split()\n",
    "    actual = filter_data(actual_answer).split()\n",
    "    common_token_counts = Counter(predicted) & Counter(actual)\n",
    "    num_common_tokens = sum(common_token_counts.values())\n",
    "    if num_common_tokens > 0:\n",
    "        precision = num_common_tokens / len(predicted)\n",
    "        recall = num_common_tokens / len(actual)\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15d7b6-4f1d-46f1-af7a-5ade48d4ebde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "python_custom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
